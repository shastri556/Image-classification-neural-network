{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 8 - Neural Networks (SVHN dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background:\n",
    "\n",
    "Recognizing multi-digit numbers in photographs captured at street level is an important component of modern-day map making.\n",
    "\n",
    "The ability to automatically transcribe an address number from a geo-located patch of pixels and associate the transcribed number with a known street address helps pinpoint, with a high degree of accuracy, the location of the building it represents.\n",
    "\n",
    "In this project we use dataset with images centred around a single digit (many of the images do contain some distractors at the sides). Although we are taking a sample of the data which is simpler, it is more complex than MNIST because of the distractors.\n",
    "\n",
    "Dataset:\n",
    "\n",
    "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data formatting but comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images. \n",
    "\n",
    "Although, there are close to 6,00,000 images in this dataset, we have extracted 60,000 images  (42000 training and 18000 test images) to do this project. The data comes in a MNIST-like format of 32-by-32 RGB images centred around a single digit (many of the images do contain some distractors at the sides). File Name is SVHN_single_grey1.h5\n",
    "\n",
    "About '.h5' file format:\n",
    "\n",
    "An H5 file is a data file saved in the Hierarchical Data Format (HDF). It contains multidimensional arrays of scientific data & is designed to store and organize large amounts of data.\n",
    "\n",
    "This file format is commonly used in fields like medicine, aerospace, physics, engineering, finance, academic research, genomics, astronomy, electronics instruments.\n",
    "\n",
    "\n",
    "Project Objectives:\n",
    "\n",
    "The objective of the project is to learn how to implement a simple image classification pipeline based on the k-Nearest Neighbour and a deep neural network.\n",
    "\n",
    "● Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages) \n",
    "● Data fetching and understand the train/val/test splits \n",
    "● Implement and apply an optimal k-Nearest Neighbor (kNN) classifier\n",
    "● Print the classification metric report\n",
    "● Implement and apply a deep neural network classifier including (feedforward  neural network, RELU activations)\n",
    "● Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions)\n",
    "● Implement batch normalization for training the neural network\n",
    "● Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow and numpy libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# h5py package is used to read the hdf file format\n",
    "import h5py\n",
    "\n",
    "# we pass 'r' as parameter in below line and read the hdf file\n",
    "h5data=h5py.File('SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find what is in this file?\n",
    "\n",
    "list(h5data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that file consists of test and train components \n",
    "# test data consists of 18000 images of 32*32 pixels\n",
    "\n",
    "h5data['X_test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data consists of 42000 images of 32*32 pixels\n",
    "h5data['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a total of 60000 images of 32*32 pixels\n",
    "h5data['X_val'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5data['y_test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5data['y_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5data['y_val'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 40.558 ,  46.7917,  48.9764, ..., 112.1153, 112.9904,\n",
       "         112.1646],\n",
       "        [ 39.4379,  44.2911,  47.1768, ..., 111.0122, 110.9475,\n",
       "         109.9368],\n",
       "        [ 38.4488,  43.6394,  48.7098, ..., 109.8921, 109.9414,\n",
       "         109.1048],\n",
       "        ...,\n",
       "        [ 34.9869,  35.4707,  39.6676, ..., 109.211 , 109.9074,\n",
       "         112.7346],\n",
       "        [ 35.6602,  35.5462,  40.3193, ..., 110.9998, 112.049 ,\n",
       "         114.3431],\n",
       "        [ 36.1871,  35.4214,  40.6998, ..., 110.0169, 111.2017,\n",
       "         114.1906]],\n",
       "\n",
       "       [[115.1609, 114.161 , 113.1611, ..., 112.0302, 112.6711,\n",
       "         112.7851],\n",
       "        [110.5743, 110.2754, 108.9766, ..., 106.1448, 106.7857,\n",
       "         107.0137],\n",
       "        [102.8031, 102.5042, 101.7924, ...,  95.776 ,  95.531 ,\n",
       "          95.645 ],\n",
       "        ...,\n",
       "        [169.8457, 170.6176, 167.8028, ...,  45.1708,  55.6967,\n",
       "          62.81  ],\n",
       "        [157.7329, 157.6189, 153.8042, ...,  42.9538,  50.1811,\n",
       "          56.1805],\n",
       "        [150.3207, 149.2068, 144.8051, ...,  42.1388,  48.2522,\n",
       "          53.2517]],\n",
       "\n",
       "       [[133.255 , 134.7279, 136.3148, ..., 103.7248, 100.8391,\n",
       "         100.6111],\n",
       "        [134.2549, 135.8418, 138.3146, ..., 117.1965, 114.1968,\n",
       "         114.0828],\n",
       "        [136.2547, 135.9558, 137.4287, ..., 126.8535, 123.7398,\n",
       "         123.4409],\n",
       "        ...,\n",
       "        [135.4136, 133.4847, 131.2569, ..., 129.0552, 131.642 ,\n",
       "         133.4569],\n",
       "        [129.3972, 128.7671, 127.8381, ..., 128.5822, 129.2832,\n",
       "         129.9842],\n",
       "        [119.0823, 120.8649, 123.0496, ..., 128.1801, 127.8103,\n",
       "         128.2124]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[166.1898, 164.7169, 162.8311, ...,  92.9414,  97.3431,\n",
       "          97.9301],\n",
       "        [164.6029, 163.717 , 162.1301, ...,  93.0554,  97.3431,\n",
       "          97.0442],\n",
       "        [161.9021, 161.9021, 161.1302, ...,  94.1693,  97.5711,\n",
       "          97.1582],\n",
       "        ...,\n",
       "        [ 75.0679,  84.8219,  96.8638, ..., 163.9019, 163.7879,\n",
       "         163.6739],\n",
       "        [ 81.0673,  87.2947,  93.935 , ..., 163.016 , 162.788 ,\n",
       "         162.674 ],\n",
       "        [ 86.7247,  89.4794,  92.8211, ..., 162.902 , 162.788 ,\n",
       "         162.674 ]],\n",
       "\n",
       "       [[137.5778, 136.6919, 134.8061, ..., 111.1397, 109.314 ,\n",
       "         108.0152],\n",
       "        [131.5784, 130.6925, 127.9208, ..., 107.1401, 105.5424,\n",
       "         104.2436],\n",
       "        [119.8076, 118.8077, 115.0361, ..., 101.2547,  99.771 ,\n",
       "          98.8851],\n",
       "        ...,\n",
       "        [130.0238, 129.0239, 125.1383, ..., 141.3755, 141.3755,\n",
       "         140.3756],\n",
       "        [134.0234, 134.0234, 133.1375, ..., 144.4892, 143.3753,\n",
       "         142.3754],\n",
       "        [136.0232, 137.0231, 138.137 , ..., 144.7881, 142.7883,\n",
       "         141.7884]],\n",
       "\n",
       "       [[ 30.182 ,  30.182 ,  30.182 , ...,  41.1208,  42.1207,\n",
       "          42.8217],\n",
       "        [ 30.182 ,  30.182 ,  29.595 , ...,  40.1209,  41.1208,\n",
       "          41.8218],\n",
       "        [ 29.8939,  29.8939,  28.894 , ...,  39.121 ,  40.1209,\n",
       "          40.1209],\n",
       "        ...,\n",
       "        [ 31.9431,  31.9431,  31.9431, ...,  51.4958,  50.9088,\n",
       "          49.9089],\n",
       "        [ 31.1712,  31.1712,  32.0571, ...,  40.2627,  39.9638,\n",
       "          39.2628],\n",
       "        [ 31.1712,  31.1712,  32.1711, ...,  35.0891,  34.6762,\n",
       "          34.0892]]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the test data matrix \n",
    "h5data['X_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=h5data['X_train'][:]\n",
    "X_test=h5data['X_test'][:]\n",
    "y_train=h5data['y_train'][:]\n",
    "y_test=h5data['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACXBJREFUeJztndtSE10QhVcScgJBNChn5aBVWl5449P4eL6ED2FpcWN5Ao8E8EAUQwIBkvkvUl/Pzg4qaNXsov69bsZkjnRWd6/u6RlzSZIoIgzyoS/g/4xo/ICIxg+IaPyAiMYPiGj8gIjGD4ho/ICIxg+IkSxP9ujRo0SSvn79Kkkql8saHx+XJFuOjo5KkorFoiSpUCgol8tJkqjG9/f3JUlfvnyRJH369EmS9O3bN52cnEiSLl26JEm6evWqJKlWq9l5qtXqwDaVSkWS1Ov1JEmdTkfNZlOS7HgjI4OmYltJyuf7HD48PJQkPXz4MHcWe0TmB0SmzIctx8fHkvqs7nQ6kmRs9JkG613gFTD28uXLdnyODathPMfvdrt2Drb1z9Htdu38hULBvnPhfn90dDRwXWdFZH5AZMp82IMH9Ho9Yx3fEdeJo0mSGMtYB8PIEzC5VCrZOWD6lStXJKXs3t/ft+1brdbA/i5zS6XSwDkPDg4kpYznevP5vH3H8qzI1Pi4OQY6Ojqy7/hj/BDgJlyWvmFYlstl24+QRPjBeLlczozND8w1gGKxaGHHJwPge9fgfmj6E2LYCYhMmb+3tydJ2t3dldSXlYQFJCZLPOHw8NCYCfvYZnt7W1JfYkrS1NSUhRukIkuO0el0zEMIWxMTEwPXeXBwYLIRLzvNI6U+28/LeBCZHxCZMv/Hjx+SUlaXy2VjqhuvXSRJYvHXTXKsc5eFQsHWkTxZBztzuZxJQ5bA3Zf9/NjvF3z/gsj8gMiU+cRmlEi1WjU1QhwHrqxke1QKwBPcgohtWcL4drstqe99fpHmF3quwuLYeIXbVgC/KsT+hMj8gMiU+aichYUFSX3mwXyUBwwlHpdKJY2NjUlKFcvPnz8lpYwFo6Oj1mpwiyp3n62tLTsezPeLt0KhYCx2c4WUegLXl8/nh+qEsyJT4yPfXPjFi+/mSZLYv1lidI6H0dwwhkGRt/V6XZK0sbGhqakpSekPjoHd0EKIY+lLTfez/zecFTHsBESmzCcxuUyGWX6ycrchyeHqtArYlzBSLpfNC/AKkvyHDx8kSe/evbPQBvMJg3zO5XLmXX7YAXjo3xZYUmR+UGTKfD8ZHhwcWGeR5Ec5D4NPTk4GZKKUJk/Yx92q8fFxYyLHZZ/v379L6id9tsFjpqenBz6PjY0N5Rm3E+sjSs0LiEyZTyGFEjk+Ph6K335PvNfrGfNRLnzGOyYnJ21f1rHk+OSL4+NjywMUVYuLi5Kk+fl5SX3v41rxRDzIZ7mbC87bcojMD4hMmb+0tCRpsG1MyxcWzs7OSkrjb7vdNtbt7OxISr3k7t27ktKWcKvVsnzw6tUrSdKLFy/sONLwFIKUtp03NjYk9dl848YNSWmR5t+fhfmFQuHUGytnQWR+QGTK/Hv37klKlUij0TA9DfuuX78uKY2fnU7H2hLEb7xiZmZGUuo1m5ubVsm+fv1aUl/XS6lqmZmZGWhduOf++PGjpL56WllZkfR7lePjtEmL3yFT49++fVuS9PLlS0l9V8agLEmG7mAUBsQAjINgPAy7t7en9+/fS+r/EFIqSwlN8/PzajQaktJCjG1Aq9WyMMMPzaCX3+Pp9XoDIeg8iGEnIDJlPpIQNu3t7Q01yUiMsGh7e9vYTDF069YtSSn7OMbOzo7W19ft2NJwC2F2dlafP3+WJFu60xRS3wtJ6oQ0X0bibf49hvMgMj8gggxNucOwMIek6s/27O7uGkNJxrSN/X03NzdtaBYgGck309PT5nnkEPaH3e1220QBucJvG7sJ+LyJFkTmB0SmzEdBwPyxsTGL28g9xr6Jv71ez7ahDYAHoJBQQ+vr61aI0SqYm5uTlDJ/cXHR4vjW1paktOnmtq7JQXig30KG7a7COW/8j8wPiCBqx2160Q4GqBSYNz09PaRy0Pkom2fPnkmSnj9/bp5DK4N2BZ+Xlpbs/H7zDM8cGRkxT2Rbf2bI1fa/uuHyJ2RqfHr23ENNksSSKYZANhJ2JicnrTIm3LDuzZs3kqSnT59K6vdzSJokVcKPm6xJooQfSME1lMtlIwFFn3uXS0qNnyRJ7O1cRGTKfBISHnB0dDTk1shImLqysqKbN29KSsMC3kILga5nLpezkESoIqwxjpgkiXnF6uqqpJTxyMtms2ntBK4Hbzkt/JyX8SAyPyAyZT7SEGm3tramJ0+eSErZfO3aNUlpB/TBgwfGYpIgnUvkH3395eVlayOwP4x3nzSEzffv35eUsprcsbOzY9vT3fSTqVt0se688zuR+QERZEScXnu9Xh+6w8SEA4poYWHBWgRv376VlHoHOQB2SukzWPT6yR3kGWl47JD2NQqmWCwODfD6/Xy30eaPrJ8VkfkBkSnzifWwsFarWcsApsN8iqK5uTlTLMRmPIiCCmXSarXs2L525/t8Pm9MB3iCO0FBrqAA85l/WnvhvMzP1Pj8QRhmcnLSiir+OIyFZMzn80MDtoQH9kUiHh4eDj28jNHdTiaGw9j+vYRms2nJnXX+AK5rfK49FlkXCJkyn/BBN7FSqViCBHgF246OjlpihY20F2AapX+xWDTvIpTQJnCfpyXREr5oISB36/W6JVHCIt1Rjus+6/W3Q7OR+QGRKfORiiTKRqNhhRexGZYzYSANS0M8gAQOu7vdrsV2coY/HeGen/39p1d2d3fteji2D/+peCkWWRcKmTL/8ePHktIYS+yXht+VgOSsVqvGTO7P+gOzYGJiwgquO3fuSErzgstQ/7UyeAv5plarWS7ypxdOexfD3z6TG5kfEJkyf21tTVLK4EajMfQ+BVjoKhi0NmrEf3Icb6lWq6b9UTK8nwGW12o1OweFnd/wS5LE7oDRnvBbyf9SXIHI/IDIlPkwnjkZ9wE2ynj/xUaFQsFiMXnAryRhtVs30FhbXl6WlDbjSqWSbe8qICn1vtXVVasz/Puz/rsckiT564figjyT5RrRfxT/tCXGJhT4rwMg1LTb7aHJY+528YNLqXQlzCBr3dDivxYG+CHmX4anYtgJiEyZT1+eBJnP5y0EwFgYh8SrVCqW5PAYtiHxukWW//ShPz7Y7XbN2wgX/oCU+9Ik/04YiOOCFxy5+H+mhENkfkBE4wdENH5AROMHRDR+QETjB0Q0fkBE4wdENH5AROMHRDR+QETjB0Q0fkBE4wdENH5AROMHRDR+QETjB0Q0fkBE4wdENH5AROMHRDR+QPwHASdWK8AEa70AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels for above images: [2 6 7 4 4]\n"
     ]
    }
   ],
   "source": [
    "# each image has a label defined:\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(X_train[i],cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "print('labels for above images: %s' % (y_train[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set (42000, 1024) (42000,)\n",
      "Test Set (18000, 1024) (18000,)\n"
     ]
    }
   ],
   "source": [
    "# reshaping the data from 2D to 1D (32*32=1024)\n",
    "\n",
    "X_train=X_train.reshape(X_train.shape[0],1024)\n",
    "X_test=X_test.reshape(X_test.shape[0],1024)\n",
    "\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0\n",
    "\n",
    "print('Training Set', X_train.shape,y_train.shape)\n",
    "print('Test Set',X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15905097, 0.18349686, 0.19206432, ..., 0.43143883, 0.4360851 ,\n",
       "        0.44780627],\n",
       "       [0.45161137, 0.44769022, 0.44376904, ..., 0.1652502 , 0.18922432,\n",
       "        0.20883021],\n",
       "       [0.52256864, 0.52834475, 0.53456783, ..., 0.50266707, 0.5012169 ,\n",
       "        0.5027937 ],\n",
       "       ...,\n",
       "       [0.6517247 , 0.64594865, 0.6385533 , ..., 0.6388313 , 0.6383843 ,\n",
       "        0.63793725],\n",
       "       [0.5395208 , 0.5360466 , 0.5286514 , ..., 0.56779647, 0.5599541 ,\n",
       "        0.55603296],\n",
       "       [0.11836078, 0.11836078, 0.11836078, ..., 0.13760431, 0.1359851 ,\n",
       "        0.13368313]], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at the test data matrix after re-shaping\n",
    "X_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test[0] defines a single value i.e. an image of value 1:\n",
    "\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "from keras.utils import np_utils\n",
    "y_train1=np_utils.to_categorical(y_train)\n",
    "y_test1=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after encoding the values are represented as array like \n",
    "# 1 :- [0,1,0,0,0,0,0,0,0,0]\n",
    "# 2 :- [0,0,1,0,0,0,0,0,0,0]..... and so on.\n",
    "\n",
    "y_test1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test[0] still represents an image of value 1, after encoding this is how it is defined:\n",
    "y_test1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of classes\n",
    "num_classes=y_test1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1024)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set has now 42000 images with 1D (32*32=1024)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening\n",
    "x_tr=[]\n",
    "for i in range(42000):\n",
    "    x_tr.append(X_train[i,:].flatten())\n",
    "x_te=[]\n",
    "for i in range(18000):\n",
    "    x_te.append(X_test[i,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a sample\n",
    "x_tr=x_tr[:5000]\n",
    "x_te=x_te[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr=y_train[:5000]\n",
    "y_te=y_test[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NEAREST NEIGHBOUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking accuracy for different k vaues, keeping in view the below points:\n",
    "\n",
    "K value should be odd as number of classes is even and k should not be in multiples of the number of classes\n",
    "\n",
    "Should not be too small or too large as a small value of k means that noise will have a higher influence on the result. \n",
    "A large value make it computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compute the accuracy for different k values starting from 1 to 31 with a step of 2 i.e. k = 1,3,5,7,9..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3382\n"
     ]
    }
   ],
   "source": [
    "# k=1: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=1,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3302\n"
     ]
    }
   ],
   "source": [
    "# k=3: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=3,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3496\n"
     ]
    }
   ],
   "source": [
    "# k=5: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=5,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3534\n"
     ]
    }
   ],
   "source": [
    "# k=7: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=7,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3636\n"
     ]
    }
   ],
   "source": [
    "# k=9: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=9,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3726\n"
     ]
    }
   ],
   "source": [
    "# k=11: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=11,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3758\n"
     ]
    }
   ],
   "source": [
    "# k=13: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=13,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3792\n"
     ]
    }
   ],
   "source": [
    "# k=15: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=15,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3822\n"
     ]
    }
   ],
   "source": [
    "# k=17: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=17,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3822\n"
     ]
    }
   ],
   "source": [
    "# k=19: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=19,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3814\n"
     ]
    }
   ],
   "source": [
    "# k=21: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=21,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3858\n"
     ]
    }
   ],
   "source": [
    "# k=23: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=23,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3828\n"
     ]
    }
   ],
   "source": [
    "# k=25: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=25,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3846\n"
     ]
    }
   ],
   "source": [
    "# k=27: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=27,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3816\n"
     ]
    }
   ],
   "source": [
    "# k=29: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=29,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3784\n"
     ]
    }
   ],
   "source": [
    "# k=31: \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "NNH=KNeighborsClassifier(n_neighbors=31,weights='uniform', metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "predicted_labels=NNH.predict(x_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ascore=accuracy_score(y_te,predicted_labels)\n",
    "MSE=1-ascore\n",
    "print(ascore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing all the above results, we observe that the maximum accuracy (38.58%) was attained at k =23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for k=23:\n",
    "NNH=KNeighborsClassifier(n_neighbors=23,weights='uniform',metric='euclidean')\n",
    "NNH.fit(x_tr,y_tr)\n",
    "pred=NNH.predict(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[289,  33,  42,  55,  46,  74,  83,  42,  93, 110],\n",
       "       [ 27, 294,  69,  94,  76,  60,  46,  58,  51,  61],\n",
       "       [ 12,  18, 191,  39,  15,  25,  18,  48,  23,  30],\n",
       "       [  7,  23,  36, 121,  18,  60,  30,  29,  31,  23],\n",
       "       [ 27,  29,  28,  16, 260,  19,  46,  12,  43,  21],\n",
       "       [ 24,  27,  22,  51,  18, 125,  42,  19,  25,  27],\n",
       "       [ 34,  18,  16,  20,  42,  57, 165,  19,  74,  36],\n",
       "       [ 21,  34,  37,  30,  10,  17,  17, 221,  13,  23],\n",
       "       [ 20,   7,  12,  17,   8,  47,  36,   9, 116,  21],\n",
       "       [ 42,  20,  34,  18,  19,  38,  33,  19,  52, 147]], dtype=int64)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing confusion matrix:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(pred,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# Initializing SEQUENTIAL model\n",
    "model=tf.keras.models.Sequential()\n",
    "\n",
    "# Batch normalization:\n",
    "\n",
    "# Improves gradient flow through the network, allows higher learning rates & reduces the strong dependence on initialization\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(1024,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding four hidden layers: with 256,64,64 and 32 neurons respectively.\n",
    "# There are different types of activation functions: Sigmoid, Tanh, ReLU, Leaky ReLU.\n",
    "# We are using the activation function 'relu' here as it has the following advantages:\n",
    "# Very simple and efficient, Have 6x times better convergence than tanh and sigmoid function & is very efficient in computation\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu')) \n",
    "\n",
    "# Adding ouput layer, with number of classes or outputs = 10 (between 0 to 9):\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model:\n",
    "from keras.layers import Dropout, MaxPooling2D\n",
    "# introducing learning rate decay, lr default is 0.01\n",
    "adam=tf.keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_v1 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 289,514\n",
      "Trainable params: 287,466\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reviewing the Model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 1.5170 - acc: 0.4826 - val_loss: 1.2166 - val_acc: 0.6764\n",
      "Epoch 2/30\n",
      " - 5s - loss: 0.9671 - acc: 0.6975 - val_loss: 0.8697 - val_acc: 0.7342\n",
      "Epoch 3/30\n",
      " - 5s - loss: 0.8046 - acc: 0.7506 - val_loss: 0.8003 - val_acc: 0.7559\n",
      "Epoch 4/30\n",
      " - 5s - loss: 0.7127 - acc: 0.7786 - val_loss: 0.7310 - val_acc: 0.7825\n",
      "Epoch 5/30\n",
      " - 5s - loss: 0.6507 - acc: 0.7986 - val_loss: 0.7005 - val_acc: 0.7923\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.6027 - acc: 0.8150 - val_loss: 0.7095 - val_acc: 0.7911\n",
      "Epoch 7/30\n",
      " - 5s - loss: 0.5701 - acc: 0.8221 - val_loss: 0.6610 - val_acc: 0.8041\n",
      "Epoch 8/30\n",
      " - 4s - loss: 0.5406 - acc: 0.8308 - val_loss: 0.6819 - val_acc: 0.8020\n",
      "Epoch 9/30\n",
      " - 4s - loss: 0.5182 - acc: 0.8377 - val_loss: 0.6428 - val_acc: 0.8121\n",
      "Epoch 10/30\n",
      " - 5s - loss: 0.4812 - acc: 0.8497 - val_loss: 0.6313 - val_acc: 0.8161\n",
      "Epoch 11/30\n",
      " - 5s - loss: 0.4754 - acc: 0.8512 - val_loss: 0.6324 - val_acc: 0.8207\n",
      "Epoch 12/30\n",
      " - 5s - loss: 0.4436 - acc: 0.8617 - val_loss: 0.6265 - val_acc: 0.8228\n",
      "Epoch 13/30\n",
      " - 5s - loss: 0.4362 - acc: 0.8625 - val_loss: 0.6230 - val_acc: 0.8258\n",
      "Epoch 14/30\n",
      " - 5s - loss: 0.4142 - acc: 0.8691 - val_loss: 0.6345 - val_acc: 0.8225\n",
      "Epoch 15/30\n",
      " - 5s - loss: 0.4088 - acc: 0.8730 - val_loss: 0.6086 - val_acc: 0.8303\n",
      "Epoch 16/30\n",
      " - 5s - loss: 0.3883 - acc: 0.8785 - val_loss: 0.6258 - val_acc: 0.8262\n",
      "Epoch 17/30\n",
      " - 5s - loss: 0.3755 - acc: 0.8831 - val_loss: 0.6210 - val_acc: 0.8272\n",
      "Epoch 18/30\n",
      " - 5s - loss: 0.3648 - acc: 0.8845 - val_loss: 0.6202 - val_acc: 0.8297\n",
      "Epoch 19/30\n",
      " - 5s - loss: 0.3591 - acc: 0.8855 - val_loss: 0.6340 - val_acc: 0.8304\n",
      "Epoch 20/30\n",
      " - 5s - loss: 0.3422 - acc: 0.8917 - val_loss: 0.6299 - val_acc: 0.8321\n",
      "Epoch 21/30\n",
      " - 5s - loss: 0.3296 - acc: 0.8938 - val_loss: 0.6350 - val_acc: 0.8337\n",
      "Epoch 22/30\n",
      " - 4s - loss: 0.3294 - acc: 0.8940 - val_loss: 0.6578 - val_acc: 0.8277\n",
      "Epoch 23/30\n",
      " - 4s - loss: 0.3133 - acc: 0.9008 - val_loss: 0.6747 - val_acc: 0.8267\n",
      "Epoch 24/30\n",
      " - 5s - loss: 0.3131 - acc: 0.9003 - val_loss: 0.6232 - val_acc: 0.8367\n",
      "Epoch 25/30\n",
      " - 5s - loss: 0.3091 - acc: 0.9011 - val_loss: 0.6411 - val_acc: 0.8329\n",
      "Epoch 26/30\n",
      " - 5s - loss: 0.2985 - acc: 0.9049 - val_loss: 0.6546 - val_acc: 0.8354\n",
      "Epoch 27/30\n",
      " - 5s - loss: 0.2874 - acc: 0.9086 - val_loss: 0.6588 - val_acc: 0.8317\n",
      "Epoch 28/30\n",
      " - 4s - loss: 0.2701 - acc: 0.9139 - val_loss: 0.6840 - val_acc: 0.8310\n",
      "Epoch 29/30\n",
      " - 4s - loss: 0.2815 - acc: 0.9093 - val_loss: 0.6307 - val_acc: 0.8428\n",
      "Epoch 30/30\n",
      " - 4s - loss: 0.2696 - acc: 0.9143 - val_loss: 0.6668 - val_acc: 0.8345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1643eebd828>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model. Hyperparameters used: \n",
    "\n",
    "# input training data (X_train) and the actual output (y_train1)\n",
    "\n",
    "# validation_data is the test data (X_test, y_test1)\n",
    "\n",
    "# epochs: number of iterations = 30\n",
    "\n",
    "# batch size of 200 means: 48000/200 = 240 batches\n",
    "\n",
    "# In each epoch/iteration model will run 240 times\n",
    "\n",
    "model.fit(X_train,y_train1, validation_data=(X_test,y_test1),epochs=30,batch_size=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the activation function to SIGMOID:\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='sigmoid')) \n",
    "\n",
    "# Adding ouput layers, with number of classes or outputs=10:\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model:\n",
    "from keras.layers import Dropout, MaxPooling2D\n",
    "adam=tf.keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      " - 7s - loss: 2.2557 - acc: 0.1710 - val_loss: 2.0370 - val_acc: 0.3546\n",
      "Epoch 2/30\n",
      " - 6s - loss: 1.5537 - acc: 0.6336 - val_loss: 1.2022 - val_acc: 0.7589\n",
      "Epoch 3/30\n",
      " - 6s - loss: 1.0981 - acc: 0.7690 - val_loss: 1.0813 - val_acc: 0.7573\n",
      "Epoch 4/30\n",
      " - 5s - loss: 0.8385 - acc: 0.8175 - val_loss: 0.8737 - val_acc: 0.8017\n",
      "Epoch 5/30\n",
      " - 5s - loss: 0.7483 - acc: 0.8308 - val_loss: 0.8387 - val_acc: 0.8054\n",
      "Epoch 6/30\n",
      " - 5s - loss: 0.6593 - acc: 0.8492 - val_loss: 0.7903 - val_acc: 0.8098\n",
      "Epoch 7/30\n",
      " - 5s - loss: 0.5936 - acc: 0.8604 - val_loss: 0.6998 - val_acc: 0.8326\n",
      "Epoch 8/30\n",
      " - 5s - loss: 0.5285 - acc: 0.8726 - val_loss: 0.6657 - val_acc: 0.8327\n",
      "Epoch 9/30\n",
      " - 5s - loss: 0.4733 - acc: 0.8824 - val_loss: 0.6643 - val_acc: 0.8328\n",
      "Epoch 10/30\n",
      " - 6s - loss: 0.4462 - acc: 0.8865 - val_loss: 0.6639 - val_acc: 0.8337\n",
      "Epoch 11/30\n",
      " - 5s - loss: 0.4232 - acc: 0.8911 - val_loss: 0.6722 - val_acc: 0.8289\n",
      "Epoch 12/30\n",
      " - 5s - loss: 0.4073 - acc: 0.8938 - val_loss: 0.6268 - val_acc: 0.8386\n",
      "Epoch 13/30\n",
      " - 5s - loss: 0.3834 - acc: 0.8997 - val_loss: 0.6527 - val_acc: 0.8352\n",
      "Epoch 14/30\n",
      " - 5s - loss: 0.3711 - acc: 0.9030 - val_loss: 0.6753 - val_acc: 0.8267\n",
      "Epoch 15/30\n",
      " - 5s - loss: 0.3577 - acc: 0.9053 - val_loss: 0.6368 - val_acc: 0.8330\n",
      "Epoch 16/30\n",
      " - 5s - loss: 0.3560 - acc: 0.9055 - val_loss: 0.6152 - val_acc: 0.8419\n",
      "Epoch 17/30\n",
      " - 5s - loss: 0.3395 - acc: 0.9082 - val_loss: 0.6404 - val_acc: 0.8393\n",
      "Epoch 18/30\n",
      " - 5s - loss: 0.3335 - acc: 0.9094 - val_loss: 0.6153 - val_acc: 0.8394\n",
      "Epoch 19/30\n",
      " - 6s - loss: 0.3253 - acc: 0.9126 - val_loss: 0.6217 - val_acc: 0.8407\n",
      "Epoch 20/30\n",
      " - 5s - loss: 0.3206 - acc: 0.9128 - val_loss: 0.6414 - val_acc: 0.8401\n",
      "Epoch 21/30\n",
      " - 5s - loss: 0.3131 - acc: 0.9145 - val_loss: 0.6018 - val_acc: 0.8493\n",
      "Epoch 22/30\n",
      " - 5s - loss: 0.3068 - acc: 0.9145 - val_loss: 0.6169 - val_acc: 0.8449\n",
      "Epoch 23/30\n",
      " - 5s - loss: 0.3023 - acc: 0.9157 - val_loss: 0.6370 - val_acc: 0.8387\n",
      "Epoch 24/30\n",
      " - 5s - loss: 0.2937 - acc: 0.9193 - val_loss: 0.6324 - val_acc: 0.8456\n",
      "Epoch 25/30\n",
      " - 5s - loss: 0.2860 - acc: 0.9204 - val_loss: 0.6439 - val_acc: 0.8412\n",
      "Epoch 26/30\n",
      " - 5s - loss: 0.2823 - acc: 0.9216 - val_loss: 0.6282 - val_acc: 0.8428\n",
      "Epoch 27/30\n",
      " - 6s - loss: 0.2750 - acc: 0.9246 - val_loss: 0.6386 - val_acc: 0.8376\n",
      "Epoch 28/30\n",
      " - 6s - loss: 0.2738 - acc: 0.9238 - val_loss: 0.6340 - val_acc: 0.8437\n",
      "Epoch 29/30\n",
      " - 6s - loss: 0.2684 - acc: 0.9254 - val_loss: 0.6260 - val_acc: 0.8426\n",
      "Epoch 30/30\n",
      " - 6s - loss: 0.2679 - acc: 0.9250 - val_loss: 0.6283 - val_acc: 0.8474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1644f082e10>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model:\n",
    "\n",
    "model.fit(X_train,y_train1, validation_data=(X_test,y_test1),epochs=30,batch_size=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 2.0551 - acc: 0.2390 - val_loss: 1.6770 - val_acc: 0.5308\n",
      "Epoch 2/30\n",
      " - 5s - loss: 1.4648 - acc: 0.4991 - val_loss: 1.1508 - val_acc: 0.6625\n",
      "Epoch 3/30\n",
      " - 5s - loss: 1.2539 - acc: 0.5846 - val_loss: 0.9718 - val_acc: 0.7064\n",
      "Epoch 4/30\n",
      " - 5s - loss: 1.1233 - acc: 0.6330 - val_loss: 0.8765 - val_acc: 0.7378\n",
      "Epoch 5/30\n",
      " - 5s - loss: 1.0349 - acc: 0.6631 - val_loss: 0.8121 - val_acc: 0.7553\n",
      "Epoch 6/30\n",
      " - 5s - loss: 0.9497 - acc: 0.6922 - val_loss: 0.7707 - val_acc: 0.7688\n",
      "Epoch 7/30\n",
      " - 5s - loss: 0.8862 - acc: 0.7158 - val_loss: 0.7043 - val_acc: 0.7884\n",
      "Epoch 8/30\n",
      " - 5s - loss: 0.8386 - acc: 0.7347 - val_loss: 0.6777 - val_acc: 0.7962\n",
      "Epoch 9/30\n",
      " - 5s - loss: 0.7877 - acc: 0.7531 - val_loss: 0.6626 - val_acc: 0.7990\n",
      "Epoch 10/30\n",
      " - 5s - loss: 0.7430 - acc: 0.7673 - val_loss: 0.6340 - val_acc: 0.8102\n",
      "Epoch 11/30\n",
      " - 5s - loss: 0.7198 - acc: 0.7745 - val_loss: 0.6484 - val_acc: 0.8044\n",
      "Epoch 12/30\n",
      " - 5s - loss: 0.6918 - acc: 0.7828 - val_loss: 0.6205 - val_acc: 0.8127\n",
      "Epoch 13/30\n",
      " - 4s - loss: 0.6703 - acc: 0.7918 - val_loss: 0.5820 - val_acc: 0.8251\n",
      "Epoch 14/30\n",
      " - 5s - loss: 0.6381 - acc: 0.8026 - val_loss: 0.5878 - val_acc: 0.8236\n",
      "Epoch 15/30\n",
      " - 5s - loss: 0.6294 - acc: 0.8034 - val_loss: 0.5702 - val_acc: 0.8307\n",
      "Epoch 16/30\n",
      " - 5s - loss: 0.6044 - acc: 0.8123 - val_loss: 0.5832 - val_acc: 0.8265\n",
      "Epoch 17/30\n",
      " - 5s - loss: 0.5835 - acc: 0.8184 - val_loss: 0.5710 - val_acc: 0.8291\n",
      "Epoch 18/30\n",
      " - 5s - loss: 0.5680 - acc: 0.8263 - val_loss: 0.5474 - val_acc: 0.8346\n",
      "Epoch 19/30\n",
      " - 5s - loss: 0.5650 - acc: 0.8248 - val_loss: 0.5409 - val_acc: 0.8384\n",
      "Epoch 20/30\n",
      " - 5s - loss: 0.5430 - acc: 0.8327 - val_loss: 0.5282 - val_acc: 0.8402\n",
      "Epoch 21/30\n",
      " - 5s - loss: 0.5384 - acc: 0.8333 - val_loss: 0.5453 - val_acc: 0.8394\n",
      "Epoch 22/30\n",
      " - 5s - loss: 0.5232 - acc: 0.8390 - val_loss: 0.5219 - val_acc: 0.8430\n",
      "Epoch 23/30\n",
      " - 5s - loss: 0.5217 - acc: 0.8372 - val_loss: 0.5332 - val_acc: 0.8413\n",
      "Epoch 24/30\n",
      " - 5s - loss: 0.5073 - acc: 0.8434 - val_loss: 0.5238 - val_acc: 0.8432\n",
      "Epoch 25/30\n",
      " - 5s - loss: 0.4994 - acc: 0.8451 - val_loss: 0.5275 - val_acc: 0.8446\n",
      "Epoch 26/30\n",
      " - 5s - loss: 0.4877 - acc: 0.8479 - val_loss: 0.5222 - val_acc: 0.8453\n",
      "Epoch 27/30\n",
      " - 5s - loss: 0.4781 - acc: 0.8521 - val_loss: 0.5177 - val_acc: 0.8468\n",
      "Epoch 28/30\n",
      " - 5s - loss: 0.4760 - acc: 0.8529 - val_loss: 0.5273 - val_acc: 0.8433\n",
      "Epoch 29/30\n",
      " - 5s - loss: 0.4672 - acc: 0.8552 - val_loss: 0.5248 - val_acc: 0.8476\n",
      "Epoch 30/30\n",
      " - 5s - loss: 0.4653 - acc: 0.8566 - val_loss: 0.5185 - val_acc: 0.8471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1646921bb00>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introducing few Dropouts in hidden layers and training the model:\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(1024,)))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "# adding a random dropout value in second hidden layer: \n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "# adding a dropout value in third hidden layer: \n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu')) \n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "from keras.layers import Dropout, MaxPooling2D\n",
    "\n",
    "adam=tf.keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train1, validation_data=(X_test,y_test1),epochs=30,batch_size=200,verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations | Comparisions on K-NN and Deep Learning Model:\n",
    "\n",
    "1. K-NN model gave very low accuracy percentage i.e. 38.58% and as the sample size increases it requires more computational time \n",
    "   compared to the deep learning model\n",
    "\n",
    "2. Used both 'relu' and 'sigmoid' activation functions, learning rate decay & dropouts to train the deep learning model\n",
    "\n",
    "3. 'relu' activation function gave slightly better accuracy percentages than the 'sigmoid' activation function as seen above\n",
    "\n",
    "4. The deep learning model can be more fine tuned by changing diff. hyperparameters like epochs, batch-size etc\n",
    "\n",
    "5. Dropouts is a regularization method that approximates training a large number of neural networks with different architectures   \n",
    "   in parallel.During training, some number of layer outputs are randomly ignored or dropped out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
